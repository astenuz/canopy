{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import feather\n",
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load secop data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secop = pd.read_pickle('../data/secop_union_all.pickle')\n",
    "secop = secop.drop(['urlproceso'], axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.parsing.preprocessing as gsp\n",
    "from toolz import pipe\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopset = stopwords.words('spanish')\n",
    "remove_stopwords_spanish = lambda s: ' '.join([w for w in s.split() if w not in stopset])\n",
    "\n",
    "preproc_filters = [\n",
    "    gsp.strip_non_alphanum,\n",
    "    lambda s: gsp.strip_short(s, minsize=4),\n",
    "    gsp.strip_multiple_whitespaces,\n",
    "    remove_stopwords_spanish\n",
    "]\n",
    "\n",
    "\n",
    "preproc_function = lambda s: pipe(s, *preproc_filters)\n",
    "# gsp.preprocess_string('asdgasgasg.asdhgasdh.fdh.sdfh. sdfgh.dfsh. dsf. dfh.;;l', filters = preproc_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'asdgasgasg 45 63 gahfdh 43623642.asdhgasdh.fdh.sdfh. sdfgh.dfsh. dsf. dfh.;;l'\n",
    "preproc_function(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secop['clean_description'] = secop.descripcion_del_proceso.apply(preproc_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build dictionary and corpus with gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = secop.clean_description.str.split()\n",
    "\n",
    "dictionary = Dictionary(documents)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.7)\n",
    "\n",
    "corpus = [dictionary.doc2bow(sent) for sent in documents]\n",
    "vocab = list(dictionary.values()) #list of terms in the dictionary\n",
    "vocab_set = set(dictionary.values()) #list of terms in the dictionary\n",
    "\n",
    "# vocab_tf = [dict(i) for i in corpus]\n",
    "# vocab_tf = list(pd.DataFrame(vocab_tf).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "flatten = itertools.chain.from_iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = secop.clean_description.str.split()\n",
    "documents = documents.apply(lambda words: [w for w in words if w in vocab_set])\n",
    "\n",
    "word_counter = Counter()\n",
    "word_counter.update(flatten(documents))\n",
    "#for doc in documents:\n",
    "#    word_counter.update(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = df = pd.DataFrame.from_dict(word_counter, orient='index').reset_index()\n",
    "word_counts.columns = ['word', 'n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts.sort_values('n', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(word_counts\n",
    "    .assign(single = lambda x: x.n==1)\n",
    "    .groupby('single').count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "Spacy tests. maybe this will be useful for lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"es_core_news_md\", disable=['tagger', 'parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('esto puede ser un texto para Maria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join([w.lemma_ for w in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "process the descriptions with stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_docs = pd.Series(nlp.pipe(secop.clean_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_descriptions = clean_docs.apply(lambda doc: ' '.join([w.lemma_ for w in doc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secop['stemmed_descriptions'] = stemmed_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save processed text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transparencia",
   "language": "python",
   "name": "transparencia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
